{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29c7c2b-170f-4213-a076-1f1c0aca1835",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Runtime\n",
    "Calls the ML models, handles training, loads in the dataset, using all the other methods present in ./Experiments and ./Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce342f52-3913-4e20-b1e3-523100dd57b9",
   "metadata": {},
   "source": [
    "## Methods and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c85364-2d68-45e0-a6c9-b427b6192508",
   "metadata": {},
   "source": [
    "## Argument and Configuration Handler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976df32-2cae-42f0-a7df-6fcd596689f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select one of the following models to train on the dataset: CDIL  DIL  TCN  CNN  Deformable  LSTM  GRU  "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Selection: CDIL\n"
     ]
    }
   ],
   "source": [
    "# Determine MODEL to use\n",
    "MODEL = 'null'\n",
    "models = ['CDIL', 'DIL', 'TCN', 'CNN', 'Deformable', 'LSTM', 'GRU']\n",
    "while MODEL not in models:\n",
    "    print('Select one of the following models to train on the dataset: ', end='')\n",
    "    for i in models:\n",
    "        print(i, ' ', end='')\n",
    "    MODEL = input('Selection:')\n",
    "\n",
    "\n",
    "# Configure device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Using WANDB for visualization of validation and performance\n",
    "wandb.init(project='DeFungi', name=MODEL, entity=\"jacob-davidian\")\n",
    "WANDB = wandb\n",
    "\n",
    "# Config parameters\n",
    "cfg_training = config['training']\n",
    "cfg_model = config['models']\n",
    "\n",
    "BATCH_SIZE = cfg_training['batch_size']\n",
    "NUM_CLASSES = cfg_model['n_class']\n",
    "SEQ_LEN = cfg_model['n_length']\n",
    "FIX_LENGTH = cfg_model['fix_length']\n",
    "USE_EMBED = cfg_model['use_embedding']\n",
    "CHAR_COCAB = cfg_model['vocab_size']\n",
    "INPUT_SIZE = cfg_model['dim']\n",
    "\n",
    "LAYER = cfg_model['cnn_layer']\n",
    "NHID = cfg_model['cnn_hidden']\n",
    "KERNEL_SIZE = cfg_model['cnn_ks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e4a12-ffa3-4e6d-a46f-26d06f438ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca6b7b-9a2c-496b-831c-a5c127195f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select between Grayscale or RGB dataloading\n",
    "rgb = input('Please indicate if you would prefer RGB or Grayscale images. Enter 1 for RGB, 0 for Grayscale: ')\n",
    "\n",
    "if(int(rgb)):\n",
    "    train_loader, test_loader = DeFungiDataset('../EDA/Dataset', use_grayscale=False, batch_size=BATCH_SIZE, test_size=0.2)\n",
    "else:\n",
    "    train_loader, test_loader = DeFungiDataset('../EDA/Dataset', use_grayscale=True, batch_size=BATCH_SIZE, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1872ea1c-4def-4be3-a78f-4355b24d3ad0",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2967a04-dc68-4759-8ce6-f7366440e632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: 512\n",
      "layer:1 \t distance:3 \t size:3\n",
      "layer:2 \t distance:7 \t size:7\n",
      "layer:3 \t distance:15 \t size:15\n",
      "layer:4 \t distance:31 \t size:31\n",
      "layer:5 \t distance:63 \t size:63\n",
      "layer:6 \t distance:127 \t size:127\n",
      "layer:7 \t distance:255 \t size:255\n",
      "layer:8 \t distance:511 \t size:511\n",
      "layer:9 \t distance:1023 \t size:1023\n",
      "\n",
      "Diagram of CNN: \n",
      " CONV(\n",
      "  (embedding): Embedding(256, 64)\n",
      "  (conv): ConvPart(\n",
      "    (conv_net): Sequential(\n",
      "      (0): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hawkobo/anaconda3/envs/jupyterlab-debugger/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "# Model selection with configs \n",
    "if MODEL == 'CDIL' or MODEL == 'DIL' or MODEL == 'TCN' or MODEL == 'CNN':\n",
    "    LAYER = cfg_model['cnn_layer']\n",
    "    NHID = cfg_model['cnn_hidden']\n",
    "    KERNEL_SIZE = cfg_model['cnn_ks']\n",
    "    net = CONV(MODEL, INPUT_SIZE, CLASS, [NHID] * LAYER, KERNEL_SIZE, False, False, USE_EMBED, CHAR_COCAB, FIX_length)\n",
    "    receptive_field(seq_length=SEQ_LEN, model=MODEL, kernel_size=KERNEL_SIZE, layer=LAYER)\n",
    "elif MODEL == 'Deformable':\n",
    "    LAYER = cfg_model['cnn_layer']\n",
    "    NHID = cfg_model['cnn_hidden']\n",
    "    KERNEL_SIZE = cfg_model['cnn_ks']\n",
    "    net = CONV('CNN', INPUT_SIZE, CLASS, [NHID] * LAYER, KERNEL_SIZE, True, False, USE_EMBED, CHAR_COCAB, FIX_length)\n",
    "    receptive_field(seq_length=SEQ_LEN, model=MODEL, kernel_size=KERNEL_SIZE, layer=LAYER)\n",
    "elif MODEL == 'LSTM' or MODEL == 'GRU':\n",
    "    LAYER = cfg_model['rnn_layer']\n",
    "    NHID = cfg_model['rnn_hidden']\n",
    "    net = RNN(MODEL, INPUT_SIZE, CLASS, NHID, LAYER, USE_EMBED, CHAR_COCAB, FIX_length)\n",
    "\n",
    "net = net.to(device)\n",
    "para_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'architecture of {MODEL}: \\n{net}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de941fa3-39f9-441e-9410-5469bc3e1866",
   "metadata": {},
   "source": [
    "## Create Optimizer, Load Data (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114d17f5-4143-4278-8672-fad626a7ad44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "loss = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "\n",
    "# Data\n",
    "trainloader = DataLoader(DeFungiDataset(f'../defungi_encoded/image.train.pickle', True, label_encoder), batch_size=BATCH, shuffle=True, drop_last=False)\n",
    "valloader = DataLoader(DeFungiDataset(f'../defungi_encoded/image.dev.pickle', True, label_encoder), batch_size=BATCH, shuffle=False, drop_last=False)\n",
    "testloader = DataLoader(DeFungiDataset(f'../defungi_encoded/image.test.pickle', False, label_encoder), batch_size=BATCH, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d8a9f-4c62-44dc-b3fd-96b6c8b2538d",
   "metadata": {},
   "source": [
    "## Perform Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768da3ad-73af-493f-9c3b-0fc515fa576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "TrainModel(\n",
    "    fix_length=FIX_length,\n",
    "    net=net,\n",
    "    device=device,\n",
    "    trainloader=trainloader,\n",
    "    valloader=valloader,\n",
    "    testloader=testloader,\n",
    "    n_epochs=cfg_training['epoch'],\n",
    "    n_classes=cfg_model['n_class'],\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    loginf=loginf,\n",
    "    wandb=WANDB,\n",
    "    file_name=model_name,\n",
    "    label_encoder=label_encoder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c676f3-5024-446c-a5eb-efdb14b846e6",
   "metadata": {},
   "source": [
    "## Pass to Front-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ab622-c661-491a-8ea0-7667b0ee4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Training Results for front-end\n",
    "filename = 'fungi_classifier.sav'\n",
    "pickle.dump(f'DeFungi_{MODEL}', open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
