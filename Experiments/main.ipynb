{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29c7c2b-170f-4213-a076-1f1c0aca1835",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Runtime\n",
    "Calls the ML models, handles training, loads in the dataset, using all the other methods present in ./Experiments and ./Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce342f52-3913-4e20-b1e3-523100dd57b9",
   "metadata": {},
   "source": [
    "## Methods and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17cb786f-0f6e-4101-86ac-d6f87e1cb6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "# DataLoader, Hyperparameters, Train/Test\n",
    "%run -i defungi.ipynb\n",
    "%run -i train.ipynb\n",
    "%run -i config.ipynb\n",
    "\n",
    "# Model Architecture\n",
    "%run -i ../Models/net_conv.ipynb\n",
    "%run -i ../Models/net_conv_rf.ipynb\n",
    "%run -i ../Models/net_rnn.ipynb\n",
    "%run -i ../Models/net_xformer.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c85364-2d68-45e0-a6c9-b427b6192508",
   "metadata": {},
   "source": [
    "## Argument and Configuration Handler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0976df32-2cae-42f0-a7df-6fcd596689f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select one of the following models to train on the dataset: CDIL  DIL  TCN  CNN  Deformable  LSTM  GRU  "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Selection: CDIL\n"
     ]
    }
   ],
   "source": [
    "# Determine MODEL to use\n",
    "MODEL = 'null'\n",
    "models = ['CDIL', 'DIL', 'TCN', 'CNN', 'Deformable', 'LSTM', 'GRU']\n",
    "while MODEL not in models:\n",
    "    print('Select one of the following models to train on the dataset: ', end='')\n",
    "    for i in models:\n",
    "        print(i, ' ', end='')\n",
    "    MODEL = input('Selection:')\n",
    "\n",
    "\n",
    "# Configure device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Config parameters\n",
    "cfg_training = config['training']\n",
    "cfg_model = config['models']\n",
    "\n",
    "BATCH_SIZE = cfg_training['batch_size']\n",
    "CLASS = cfg_model['n_class']\n",
    "SEQ_LEN = cfg_model['n_length']\n",
    "FIX_LENGTH = cfg_model['fix_length']\n",
    "USE_EMBED = cfg_model['use_embedding']\n",
    "CHAR_COCAB = cfg_model['vocab_size']\n",
    "INPUT_SIZE = cfg_model['dim']\n",
    "\n",
    "LAYER = cfg_model['cnn_layer']\n",
    "NHID = cfg_model['cnn_hidden']\n",
    "KERNEL_SIZE = cfg_model['cnn_ks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211fcf7-9a3e-4aa5-b804-63fd3ef3f1d2",
   "metadata": {},
   "source": [
    "## Load WANDB for evaluation metrics & visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4cb40cb-3b7d-445e-81e6-9334225d4355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhawkhobo\u001b[0m (\u001b[33mjacob-davidian\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hawkobo/Documents/ecs171-fungal-classification/Experiments/wandb/run-20231208_213611-fmy83jfd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jacob-davidian/DeFungi/runs/fmy83jfd' target=\"_blank\">CDIL</a></strong> to <a href='https://wandb.ai/jacob-davidian/DeFungi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jacob-davidian/DeFungi' target=\"_blank\">https://wandb.ai/jacob-davidian/DeFungi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jacob-davidian/DeFungi/runs/fmy83jfd' target=\"_blank\">https://wandb.ai/jacob-davidian/DeFungi/runs/fmy83jfd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using WANDB for visualization of validation and performance\n",
    "wandb.init(project='DeFungi', name=MODEL, entity=\"jacob-davidian\")\n",
    "WANDB = wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e4a12-ffa3-4e6d-a46f-26d06f438ea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0ca6b7b-9a2c-496b-831c-a5c127195f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 3 for RGB images, 1 for grayscale:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Inputs Type: torch.LongTensor\n",
      "Labels Type: torch.LongTensor\n",
      "Inputs Shape: torch.Size([32, 750000])\n",
      "Labels Shape: torch.Size([32])\n",
      "train_loader contents: <torch.utils.data.dataloader.DataLoader object at 0x7ff8e8184190>\n",
      " test_loader contents: <torch.utils.data.dataloader.DataLoader object at 0x7ff8e8186890>\n"
     ]
    }
   ],
   "source": [
    "# Select between Grayscale or RGB dataloading\n",
    "while True:\n",
    "    rgb = input(\"Enter 3 for RGB images, 1 for grayscale: \")\n",
    "    if rgb in {'1', '3'}:\n",
    "        color_option = (rgb == '3')\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter 1 or 3.\")\n",
    "    \n",
    "train_loader, test_loader = DeFungiDataset(\n",
    "                                  '../EDA/Dataset', \n",
    "                                 use_rgb=color_option,\n",
    "                             batch_size=BATCH_SIZE, \n",
    "                                     test_size=0.2)\n",
    "\n",
    "print(f'train_loader contents: {train_loader}\\n test_loader contents: {test_loader}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1872ea1c-4def-4be3-a78f-4355b24d3ad0",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2967a04-dc68-4759-8ce6-f7366440e632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: 512\n",
      "layer:1 \t distance:3 \t size:3\n",
      "layer:2 \t distance:7 \t size:7\n",
      "layer:3 \t distance:15 \t size:15\n",
      "layer:4 \t distance:31 \t size:31\n",
      "layer:5 \t distance:63 \t size:63\n",
      "layer:6 \t distance:127 \t size:127\n",
      "layer:7 \t distance:255 \t size:255\n",
      "layer:8 \t distance:511 \t size:511\n",
      "layer:9 \t distance:1023 \t size:1023\n",
      "\n",
      "Input Shape: torch.Size([32, 1024])\n",
      "After Embedding Shape: torch.Size([32, 1024, 64])\n",
      "After Permute Shape: torch.Size([32, 64, 1024])\n",
      "architecture of CDIL: \n",
      "CONV(\n",
      "  (embedding): Embedding(64, 64)\n",
      "  (conv): ConvPart(\n",
      "    (conv_net): Sequential(\n",
      "      (0): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,), padding_mode=circular)\n",
      "        (nonlinear): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model selection with configs \n",
    "if MODEL == 'CDIL' or MODEL == 'DIL' or MODEL == 'TCN' or MODEL == 'CNN':\n",
    "    LAYER = cfg_model['cnn_layer']\n",
    "    NHID = cfg_model['cnn_hidden']\n",
    "    KERNEL_SIZE = cfg_model['cnn_ks']\n",
    "    net = CONV(MODEL, INPUT_SIZE, CLASS, [NHID] * LAYER, KERNEL_SIZE, False, False, USE_EMBED, CHAR_COCAB, FIX_LENGTH)\n",
    "    receptive_field(seq_length=SEQ_LEN, model=MODEL, kernel_size=KERNEL_SIZE, layer=LAYER)\n",
    "elif MODEL == 'Deformable':\n",
    "    LAYER = cfg_model['cnn_layer']\n",
    "    NHID = cfg_model['cnn_hidden']\n",
    "    KERNEL_SIZE = cfg_model['cnn_ks']\n",
    "    net = CONV('CNN', INPUT_SIZE, CLASS, [NHID] * LAYER, KERNEL_SIZE, True, False, USE_EMBED, CHAR_COCAB, FIX_LENGTH)\n",
    "    receptive_field(seq_length=SEQ_LEN, model=MODEL, kernel_size=KERNEL_SIZE, layer=LAYER)\n",
    "elif MODEL == 'LSTM' or MODEL == 'GRU':\n",
    "    LAYER = cfg_model['rnn_layer']\n",
    "    NHID = cfg_model['rnn_hidden']\n",
    "    net = RNN(MODEL, INPUT_SIZE, CLASS, NHID, LAYER, USE_EMBED, CHAR_COCAB, FIX_LENGTH)\n",
    "    \n",
    "net = CONV(MODEL, INPUT_SIZE, CLASS, [NHID] * LAYER, KERNEL_SIZE, False, False, USE_EMBED, INPUT_SIZE, FIX_LENGTH)\n",
    "\n",
    "# Create sample inputs\n",
    "sample_input = torch.randint(0, INPUT_SIZE, (BATCH_SIZE, SEQ_LEN))\n",
    "\n",
    "outputs = net(sample_input)\n",
    "\n",
    "net = net.to(device)\n",
    "para_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'architecture of {MODEL}: \\n{net}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d8a9f-4c62-44dc-b3fd-96b6c8b2538d",
   "metadata": {},
   "source": [
    "## Perform Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "768da3ad-73af-493f-9c3b-0fc515fa576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|                                    | 0/11 [00:04<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTrainModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_training\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_training\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWANDB\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/ipykernel_6924/4029763284.py:22\u001b[0m, in \u001b[0;36mTrainModel\u001b[0;34m(model, train_loader, test_loader, num_epochs, learning_rate, wandb)\u001b[0m\n\u001b[1;32m     18\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyterlab-debugger/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyterlab-debugger/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/ipykernel_6924/1911973182.py:145\u001b[0m, in \u001b[0;36mCONV.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_embed:\n\u001b[0;32m--> 145\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic:\n\u001b[1;32m    147\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)  \u001b[38;5;66;03m# out: num, dim, length\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyterlab-debugger/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyterlab-debugger/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyterlab-debugger/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyterlab-debugger/lib/python3.11/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "TrainModel(\n",
    "    model=net,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=cfg_training['epoch'],\n",
    "    learning_rate=cfg_training['lr'],\n",
    "    wandb=WANDB\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c676f3-5024-446c-a5eb-efdb14b846e6",
   "metadata": {},
   "source": [
    "## Pass to Front-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ab622-c661-491a-8ea0-7667b0ee4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Training Results for front-end\n",
    "filename = 'fungi_classifier.sav'\n",
    "pickle.dump(f'DeFungi_{MODEL}', open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
