{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3741cc17-ea75-4862-9708-9482f41ecd6e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9abe293f-1b3a-47fe-bfa7-662cd5c9d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def other(one_input, fix_length, device):\n",
    "    X = one_input['input_ids_0']\n",
    "    Y = one_input['label']\n",
    "    if not fix_length:\n",
    "        decision_position = torch.sum(one_input['mask_0'], dim=1).long() - 1\n",
    "    else:\n",
    "        decision_position = torch.zeros(1)\n",
    "    X, Y, mask = X.to(device), Y.to(device), decision_position.to(device)\n",
    "    return X, mask, Y\n",
    "\n",
    "\n",
    "def net_eval(fix_length, val_test, n, eval_loader, device, net, loss, loginf, n_classes, wandb):\n",
    "    \n",
    "    eval_loss = 0\n",
    "    eval_num = 0\n",
    "    eval_correct = 0\n",
    "    eval_start = datetime.now()\n",
    "    \n",
    "     # Calculate confusion matrix and metrics\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for one_input in tqdm(eval_loader, total=len(eval_loader)):\n",
    "        \n",
    "        X, mask, Y = other(one_input, fix_length, device)\n",
    "        pred = net(X, mask)\n",
    "        eval_loss += loss(pred, Y).item()\n",
    "        eval_num += len(Y)\n",
    "        \n",
    "        _, predicted = pred.max(1)\n",
    "        eval_correct += predicted.eq(Y).sum().item()\n",
    "        \n",
    "        # Extend calculated results\n",
    "        y_true.extend(Y.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "    eval_loss_mean = eval_loss / eval_num\n",
    "    eval_acc = eval_correct / eval_num * 100\n",
    "    eval_end = datetime.now()\n",
    "    eval_time = (eval_end - eval_start).total_seconds()\n",
    "    \n",
    "    loginf('{} num: {} — {} loss: {} — {} accuracy: {} — Time: {}'.format(val_test, eval_num, val_test, eval_loss_mean, val_test, eval_acc, eval_time))\n",
    "    loginf('_' * n)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "            \n",
    "    \n",
    "    # Log confusion matrix and metrics to wandb\n",
    "    wandb.log({\n",
    "            f\"{val_test}_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                  probs=None,\n",
    "                  y_true=y_true,\n",
    "                  preds=y_pred,\n",
    "                  class_names=tf.unique(one_input['label']).y.numpy()\n",
    "            ),\n",
    "            f\"{val_test}_precision\": precision,\n",
    "            f\"{val_test}_recall\": recall,\n",
    "            f\"{val_test}_f1\": f1\n",
    "    })\n",
    "\n",
    "    return eval_loss_mean, eval_acc\n",
    "\n",
    "\n",
    "def TrainModel(\n",
    "        fix_length,\n",
    "        net,\n",
    "        device,\n",
    "        trainloader,\n",
    "        valloader,\n",
    "        testloader,\n",
    "        n_epochs,\n",
    "        n_classes,\n",
    "        optimizer,\n",
    "        loss,\n",
    "        loginf,\n",
    "        wandb,\n",
    "        file_name\n",
    "):\n",
    "    saving_best = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # train\n",
    "        net.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        train_num = 0\n",
    "        t_start = datetime.now()\n",
    "        \n",
    "        for one_input in tqdm(trainloader, total=len(trainloader)):\n",
    "            optimizer.zero_grad()\n",
    "            X, mask, Y = other(one_input, fix_length, device)\n",
    "            pred = net(X, mask)\n",
    "            batch_loss = loss(pred, Y)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += batch_loss.item()\n",
    "            train_num += len(Y)\n",
    "\n",
    "        \n",
    "        train_loss_mean = train_loss / train_num\n",
    "        t_end = datetime.now()\n",
    "        epoch_time = (t_end - t_start).total_seconds()\n",
    "        loginf('Epoch: {}'.format(epoch))\n",
    "        loginf('Train num: {} — Train loss: {} — Time: {}'.format(train_num, train_loss_mean, epoch_time))\n",
    "\n",
    "        # validation and test\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            val_loss_mean, val_acc = net_eval(fix_length, 'Val', 80, valloader, device, net, loss, loginf, n_classes, wandb)\n",
    "            if val_acc >= saving_best:\n",
    "                saving_best = val_acc\n",
    "                torch.save(net.state_dict(), file_name)\n",
    "                _, test_acc = net_eval(fix_length, 'Test', 120, testloader, device, net, loss, loginf, n_classes, wandb)\n",
    "            \n",
    "        \n",
    "        wandb.log({\"train loss\": train_loss_mean,\n",
    "                       \"val loss\": val_loss_mean,\n",
    "                       \"val acc\": val_acc,\n",
    "                       \"epoch\": epoch\n",
    "                       })\n",
    "        \n",
    "\n",
    "    loginf('best test acc: {}'.format(test_acc))\n",
    "    loginf('_' * 200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
